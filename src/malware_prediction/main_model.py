import os
import socket

from benchmark import timeit, memory_monitor, cpu_monitor
from dataset import MalwareDataset
from model import MalwarePredictor
from torch import distributed as dist
from torch import nn
from torch import optim
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.dataloader import DataLoader
from train import ModelTrainer

SIZE = int(os.environ['OMPI_COMM_WORLD_SIZE'])
RANK = int(os.environ['OMPI_COMM_WORLD_RANK'])
HOSTNAME = socket.gethostname()

# TRAIN_ENCODED_CSV_PATH = f"./data/train/train_encoded_{RANK}.csv"
# TEST_ENCODED_CSV_PATH = f"./data/test/test_encoded_{RANK}.csv"

TRAIN_ENCODED_CSV_PATH = f"./data/train/train_encoded.csv"
TEST_ENCODED_CSV_PATH = f"./data/test/test_encoded.csv"


@cpu_monitor(file_name="model")
@memory_monitor(file_name="model")
@timeit(file_name="model")
def run(backend='mpi'):
    """ Initialize the distributed environment. """
    print(f"Running rank {RANK} of {SIZE} on {HOSTNAME}")
    print("Start run model:")
    dist.init_process_group(backend)
    print("Data prepared.")
    dataset = MalwareDataset.load(TRAIN_ENCODED_CSV_PATH)
    loader = DataLoader(dataset, batch_size=100)
    print("Length columns: " + str(loader.dataset.cols))
    model = DDP(MalwarePredictor(loader.dataset.cols, 100, 100, 1))
    loss = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    print("Model prepared.")
    print("Process group initialized.")
    trainer = ModelTrainer(loader, model, loss, optimizer)
    print("Trainer initialized.")
    trainer.train(20, verbose=True)
    print("Done training.")
    dist.destroy_process_group()


if __name__ == '__main__':
    run()
