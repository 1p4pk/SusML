import os
import socket
import sys
import pandas as pd

import torch
from torch.utils.data.dataloader import DataLoader
from torch import distributed as dist
from torch import nn
from torch import optim
from torch.nn.parallel import DistributedDataParallel as DDP

from dataset import MalwareDataset
from models import MalwarePredictor
from train import ModelTrainer


DATA_PATH = "./data/train.csv"
world_rank = int(os.environ['OMPI_COMM_WORLD_RANK'])
ENCODED_DATA_PATH = f"./data/result_{world_rank}.csv"


def run(backend='mpi'):
    print("Start run model:")
    dist.init_process_group(backend)
    print("Data prepared.")
    dataset = MalwareDataset.load(ENCODED_DATA_PATH)
    loader = DataLoader(dataset, batch_size=10000)
    print("Length columns: " + str(len(loader.dataset.cols)))
    model = DDP(MalwarePredictor(len(loader.dataset.cols) - 2, 100, 100, 1))
    loss = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    print("Model prepared.")
    print("Process group initialized.")
    trainer = ModelTrainer(loader, model, loss, optimizer)
    print("Trainer initialized.")
    trainer.train(20, verbose=True)
    print("Done training.")
    dist.destroy_process_group()

    # run_eval(model, X_test, y_test)


def run_eval(model, X_test, y_test):
    model.eval()

    preds = []

    with torch.no_grad():
        for val in X_test:
            y_hat = model.forward(val)
            preds.append(y_hat.argmax().item())

    df = pd.DataFrame({'Y': y_test, 'YHat': preds})
    df['Correct'] = [1 if corr == pred else 0 for corr,
                     pred in zip(df['Y'], df['YHat'])]
    print(df['Correct'].sum() / len(df))


def init_processes(fn):
    """ Initialize the distributed environment. """
    world_size = int(os.environ['OMPI_COMM_WORLD_SIZE'])
    world_rank = int(os.environ['OMPI_COMM_WORLD_RANK'])
    hostname = socket.gethostname()
    print(f"Running rank {world_rank} of {world_size} on {hostname}")
    fn()


if __name__ == '__main__':
    init_processes(run)

