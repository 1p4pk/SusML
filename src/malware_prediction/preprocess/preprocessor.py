import gc
import math
import torch
import os

import pandas as pd
from mpi4py import MPI


class Preprocessor:

    def __init__(self):
        # LOAD AND FREQUENCY-ENCODE
        self._DD = []
        self._FE = ['EngineVersion', 'AppVersion', 'AvSigVersion', 'Census_OSVersion']
        # LOAD AND ONE-HOT-ENCODE
        self._OHE = ['RtpStateBitfield', 'IsSxsPassiveMode', 'DefaultBrowsersIdentifier',
                     'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled',
                     'CountryIdentifier', 'CityIdentifier',
                     'GeoNameIdentifier', 'LocaleEnglishNameIdentifier',
                     'Processor', 'OsBuild', 'OsSuite',
                     'SmartScreen', 'Census_MDC2FormFactor',
                     'Census_OEMNameIdentifier',
                     'Census_ProcessorCoreCount',
                     'Census_ProcessorModelIdentifier',
                     'Census_PrimaryDiskTotalCapacity', 'Census_PrimaryDiskTypeName',
                     'Census_HasOpticalDiskDrive',
                     'Census_TotalPhysicalRAM', 'Census_ChassisTypeName',
                     'Census_InternalPrimaryDiagonalDisplaySizeInInches',
                     'Census_InternalPrimaryDisplayResolutionHorizontal',
                     'Census_InternalPrimaryDisplayResolutionVertical',
                     'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',
                     'Census_InternalBatteryNumberOfCharges',
                     'Census_OSEdition', 'Census_OSInstallLanguageIdentifier',
                     'Census_GenuineStateName', 'Census_ActivationChannel',
                     'Census_FirmwareManufacturerIdentifier',
                     'Census_IsTouchEnabled', 'Census_IsPenCapable',
                     'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer',
                     'Wdft_RegionIdentifier']

    def import_data(self, csv_path, nrows, use_fe=True, use_ohe=True, is_train=True):
        # LOAD ALL AS CATEGORIES
        size = int(os.environ['OMPI_COMM_WORLD_SIZE'])
        rank = int(os.environ['OMPI_COMM_WORLD_RANK'])
        dtypes = {}
        if use_fe:
            for x in self._FE:
                dtypes[x] = 'category'
        if use_ohe:
            for x in self._OHE:
                dtypes[x] = 'category'
        dtypes['MachineIdentifier'] = 'str'
        if is_train:
            dtypes['HasDetections'] = 'uint8'

        _ = gc.collect()
        # LOAD CSV FILE
        if rank == 0:
            return pd.read_csv(csv_path, usecols=dtypes.keys(), dtype=dtypes, nrows=nrows)
        end = rank * nrows + 1
        if rank == size - 1:
            if is_train:
                nrows += 8921483 % size
            else:
                nrows += 7853253 % size
        return pd.read_csv(csv_path, usecols=dtypes.keys(), dtype=dtypes, nrows=nrows, skiprows=range(1, end))

    def encode_data(self, df, use_fe=True, use_ohe=True, is_train=True):
        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        if use_fe:
            for x in self._FE:
                self._encode_FE(df, x, comm, rank, size)
            for x in self._FE:
                del df[x]
        if use_ohe:
            if is_train:
                for x in self._OHE:
                    tmp = self._encode_OHE(df, x, 0.005, 5, comm, rank, size)
                    self._DD.append(tmp)
            else:
                for x in range(len(self._OHE)):
                    self._encode_OHE_test(df, self._OHE[x], self._DD[x])
            for x in self._OHE:
                del df[x]

        _ = gc.collect()

    # CHECK FOR NAN
    @staticmethod
    def _check_nan(x):
        if isinstance(x, float):
            if math.isnan(x):
                return True
        return False

    def _get_mean(self, df, x, col, tar, comm, size):
        if self._check_nan(x):
            return comm.allreduce(df[df[col].isna()][tar].mean(), op=MPI.SUM) / size
        else:
            return comm.allreduce(df[df[col] == x][tar].mean()) / size

    # FREQUENCY ENCODING
    @staticmethod
    def _encode_FE(df, col, comm, rank, size):

        d = df[col].value_counts(dropna=False)
        data_gather = comm.gather(d, root=0)
        if rank == 0:
            for i in range(1, size):
                d = d.add(data_gather[i], fill_value=0)
        else:
            assert data_gather is None
        d = comm.bcast(d, root=0)

        n = col + "_FE"
        df[n] = (df[col].map(d).astype('int64') / d.max()).astype('uint8')
        _ = gc.collect()

    # ONE-HOT ENCODING TRAIN
    def _encode_OHE(self, df, col, filter, zvalue, comm, rank, size, tar='HasDetections', m=0.5):

        cv = df[col].value_counts(dropna=False)
        cv_gather = comm.gather(cv, root=0)
        if rank == 0:
            for i in range(1, size):
                cv = cv.add(cv_gather[i], fill_value=0)
        else:
            assert cv_gather is None
        cv = comm.bcast(cv, root=0)
        cvd = cv.to_dict()
        length = cv[:].sum()
        th = filter * length
        d = {}
        for x in cv.index:
            try:
                if cv[x] < th:
                    break
                sd = zvalue * 0.5 / math.sqrt(cv[x])
            except:
                if cvd[x] < th:
                    break
                sd = zvalue * 0.5 / math.sqrt(cvd[x])

            r = self._get_mean(df, x, col, tar, comm, size)

            if abs(r - m) > sd:
                nm = col + '_BE_' + str(x)
                if self._check_nan(x):
                    df[nm] = (df[col].isna()).astype('uint8')
                else:
                    df[nm] = (df[col] == x).astype('uint8')
                d[x] = 1
        _ = gc.collect()
        return d

    # ONE-HOT ENCODING TEST
    def _encode_OHE_test(self, df, col, dt):
        for val in dt:
            n = col + "_BE_" + str(val)
            if self._check_nan(val):
                df[n] = df[col].isna()
            else:
                df[n] = df[col] == val
            df[n] = df[n].astype('uint8')
        _ = gc.collect()

    @staticmethod
    def save_train_to_tensor(df, path_label_data, path_train_data):
        y = torch.as_tensor(df['HasDetections'].values, dtype=torch.float)
        torch.save(y, path_label_data)
        del y

        X = torch.as_tensor(df.drop('HasDetections', axis=1).drop('MachineIdentifier', axis=1).values, dtype=torch.float)
        torch.save(X, path_train_data)
        del X

    @staticmethod
    def save_test_to_tensor(df, test_data_path, machine_id_path):
        X_test = torch.as_tensor(df.drop('MachineIdentifier', axis=1).values, dtype=torch.float)
        torch.save(X_test, test_data_path)
        del X_test
        df['MachineIdentifier'].to_csv(machine_id_path, index=False)
