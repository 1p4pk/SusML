{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# LOAD AND FREQUENCY-ENCODE\n",
    "FE = ['EngineVersion','AppVersion','AvSigVersion','Census_OSVersion']\n",
    "# LOAD AND ONE-HOT-ENCODE\n",
    "\n",
    "OHE = [ 'RtpStateBitfield','IsSxsPassiveMode','DefaultBrowsersIdentifier',\n",
    "        'AVProductStatesIdentifier','AVProductsInstalled', 'AVProductsEnabled',\n",
    "        'CountryIdentifier', 'CityIdentifier', \n",
    "        'GeoNameIdentifier', 'LocaleEnglishNameIdentifier',\n",
    "        'Processor', 'OsBuild', 'OsSuite',\n",
    "        'SmartScreen','Census_MDC2FormFactor',\n",
    "        'Census_OEMNameIdentifier', \n",
    "        'Census_ProcessorCoreCount',\n",
    "        'Census_ProcessorModelIdentifier', \n",
    "        'Census_PrimaryDiskTotalCapacity', 'Census_PrimaryDiskTypeName',\n",
    "        'Census_HasOpticalDiskDrive',\n",
    "        'Census_TotalPhysicalRAM', 'Census_ChassisTypeName',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "        'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',\n",
    "        'Census_InternalBatteryNumberOfCharges',\n",
    "        'Census_OSEdition', 'Census_OSInstallLanguageIdentifier',\n",
    "        'Census_GenuineStateName','Census_ActivationChannel',\n",
    "        'Census_FirmwareManufacturerIdentifier',\n",
    "        'Census_IsTouchEnabled', 'Census_IsPenCapable',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer',\n",
    "        'Wdft_RegionIdentifier']\n",
    "\n",
    "def run_import(nrows, offset=0, use_fe=True, use_ohe=True):\n",
    "    \n",
    "    # LOAD ALL AS CATEGORIES\n",
    "    dtypes = {}\n",
    "    if use_fe:\n",
    "        for x in FE: dtypes[x] = 'category'\n",
    "    if use_ohe:\n",
    "        for x in OHE: dtypes[x] = 'category'\n",
    "    dtypes['MachineIdentifier'] = 'str'\n",
    "    dtypes['HasDetections'] = 'int8'\n",
    "    \n",
    "    # LOAD CSV FILE\n",
    "    return pd.read_csv('./data/train.csv', usecols=dtypes.keys(), dtype=dtypes, nrows=nrows, skiprows=[offset])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# CHECK FOR NAN\n",
    "def nan_check(x):\n",
    "    if isinstance(x,float):\n",
    "        if math.isnan(x):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# FREQUENCY ENCODING\n",
    "def encode_FE(df,col):\n",
    "    d = df[col].value_counts(dropna=False)\n",
    "    n = col+\"_FE\"\n",
    "    df[n] = df[col].map(d)/d.max()\n",
    "    return [n]\n",
    "\n",
    "# ONE-HOT-ENCODE ALL CATEGORY VALUES THAT COMPRISE MORE THAN\n",
    "# \"FILTER\" PERCENT OF TOTAL DATA AND HAS SIGNIFICANCE GREATER THAN \"ZVALUE\"\n",
    "def encode_OHE(df, col, filter, zvalue, tar='HasDetections', m=0.5):\n",
    "    cv = df[col].value_counts(dropna=False)\n",
    "    cvd = cv.to_dict()\n",
    "    th = filter * len(df)\n",
    "    sd = zvalue * 0.5/ math.sqrt(th)\n",
    "    n = []; d = {}\n",
    "    for x in cv.index:\n",
    "        try:\n",
    "            if cv[x]<th: break\n",
    "            sd = zvalue * 0.5/ math.sqrt(cv[x])\n",
    "        except:\n",
    "            if cvd[x]<th: break\n",
    "            sd = zvalue * 0.5/ math.sqrt(cvd[x])\n",
    "        if nan_check(x): r = df[df[col].isna()][tar].mean()\n",
    "        else: r = df[df[col]==x][tar].mean()\n",
    "        if abs(r-m)>sd:\n",
    "            nm = col+'_BE_'+str(x)\n",
    "            if nan_check(x): df[nm] = (df[col].isna()).astype('int8')\n",
    "            else: df[nm] = (df[col]==x).astype('int8')\n",
    "            n.append(nm)\n",
    "            d[x] = 1\n",
    "    return [n,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_encoding(df, use_fe=True, use_ohe=True):\n",
    "    cols = []\n",
    "    dd = []\n",
    "\n",
    "    # ENCODE NEW\n",
    "    if use_fe:\n",
    "        for x in FE:\n",
    "            cols += encode_FE(df,x)\n",
    "        for x in FE:\n",
    "            del df[x]\n",
    "    if use_ohe:\n",
    "        for x in OHE:\n",
    "            tmp = encode_OHE(df,x,0.005,5)\n",
    "            cols += tmp[0]; dd.append(tmp[1])\n",
    "        for x in OHE:\n",
    "            del df[x]\n",
    "\n",
    "    x=gc.collect()\n",
    "    return cols, dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data Preparation\n",
    "def run_preparation(df, test_size=0.2):\n",
    "    X = df.drop('HasDetections', axis=1).drop('MachineIdentifier', axis=1).values\n",
    "    y = df['HasDetections'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    y_test = torch.FloatTensor(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# Model Definition\n",
    "def run_model(input_size):\n",
    "    hidden_sizes = [100, 100, 1]\n",
    "    output_size = 1\n",
    "\n",
    "    model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.Dropout(p=.4),\n",
    "                      # nn.BatchNorm1d(num_features=hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.Dropout(p=.4),\n",
    "                      # nn.BatchNorm1d(num_features=hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    return model, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "def run_training(epochs, model, X_train, y_train, optimizer, loss):\n",
    "    print(\"runnig training...\")\n",
    "    epochs = epochs\n",
    "\n",
    "    for i in range(1, epochs+1):\n",
    "        y_hat = model(X_train)\n",
    "        output = loss(y_hat, y_train)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            print(f'Epoch: {i} Loss: {output}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Model Evaluation\n",
    "\n",
    "def run_prediction(X_test):\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val in X_test:\n",
    "            y_hat = model.forward(val)\n",
    "            preds.append(y_hat.argmax().item())\n",
    "\n",
    "    df = pd.DataFrame({'Y': y_test, 'YHat': preds})\n",
    "    df['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df['Y'], df['YHat'])]\n",
    "    df['Correct'].sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# Model distribution\n",
    "def run(rank, size):\n",
    "    ROWS=50000\n",
    "    os.environ['MASTER_ADDR']='192.168.0.4'\n",
    "    os.environ['MASTER_PORT']='49162'\n",
    "    dist.init_process_group('gloo', rank=rank, world_size=size)\n",
    "    df_train = run_import(ROWS, offset=(rank*ROWS)+1, use_ohe=False)\n",
    "    print(f\"Rank: {rank}\")\n",
    "    df_train\n",
    "    cols, _ = run_encoding(df_train, use_ohe=False)\n",
    "    X_train, X_test, y_train, y_test = run_preparation(df_train)\n",
    "    model, loss, optimizer = run_model(len(cols))\n",
    "    model = DDP(model)\n",
    "    run_training(10, model, X_train, y_train, optimizer, loss)\n",
    "    #run_prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n",
      "Rank: 0\n",
      "runnig training...\n"
     ]
    }
   ],
   "source": [
    "from torch.multiprocessing import Process\n",
    "\n",
    "size = 2\n",
    "processes = []\n",
    "for rank in range(size):\n",
    "    p = Process(target=run, args=(rank, size))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid process group specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ba6548b66689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Developer/PycharmProjects/SusML/venv/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mdestroy_process_group\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_pg_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid process group specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid process group specified"
     ]
    }
   ],
   "source": [
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
